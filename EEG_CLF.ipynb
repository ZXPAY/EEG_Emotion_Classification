{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 資料預處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"C:\\\\Users\\\\zxpay\\\\Desktop\\\\BME_Senior\\\\EEG_CLF\\\\Emotion\\\\Code\")\n",
    "import sys\n",
    "from Get_file import Get_file   # return dirpath, dirnames, filenames\n",
    "from FFT import FFT, PlotDataOnTimeDomain\n",
    "from BandPassFilter import BandPassFilter, PlotDataOnFreqDomain\n",
    "import pyedflib\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import FastICA, PCA\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "data_path = \"C:\\\\Users\\\\zxpay\\\\Desktop\\\\BME_Senior\\\\EEG_CLF\\\\Emotion\\\\database\"  # EEG Data direction\n",
    "BandPassICAFigureSavingDirection = \"C:\\\\Users\\\\zxpay\\\\Desktop\\\\BME_Senior\\\\EEG_CLF\\\\Emotion\\\\Code\\\\Fig\"\n",
    "\n",
    "# Setting parameters\n",
    "Sample_frequency = 128\n",
    "DEBUG = True\n",
    "label_size = 40\n",
    "LowerFreqCut = 1\n",
    "HigherFreqCut = 35\n",
    "BandPassOrder = 3\n",
    "channel_we_use = [2,3,4,5,6,7,8,9,10,11,12,13,14,15]   # 0~39 共40, 14 channels we use\n",
    "SAVE_FIG = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讀取檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Four Lables\n",
    "normal_label = []   # 0\n",
    "scare_label = []    # 1\n",
    "touch_label = []    # 2\n",
    "laugh_label = []    # 3\n",
    "\n",
    "#Four Signal\n",
    "normal_signal = []\n",
    "scare_signal = []\n",
    "touch_signal = []\n",
    "laugh_signal = []\n",
    "\n",
    "signal = []\n",
    "labels = []\n",
    "\n",
    "_,data_files,_ = Get_file(data_path)\n",
    "if data_files == []:\n",
    "    raise(\"Not found any files ! check your data_path\")\n",
    "else:\n",
    "    print('Get data from database ...')\n",
    "    for data in data_files:\n",
    "        _,_,file_names = Get_file(data_path+'\\\\'+data)\n",
    "        for fn in file_names:\n",
    "            if fn.split('.')[1] == 'edf':\n",
    "                fedf = pyedflib.EdfReader(data_path+'\\\\'+data+'\\\\'+fn)\n",
    "                n = fedf.signals_in_file\n",
    "                signal_labels = np.asarray(fedf.getSignalLabels())\n",
    "                sigbufs = np.zeros((n, fedf.getNSamples()[0]))\n",
    "                for i in np.arange(n):\n",
    "                    sigbufs[i, :] = fedf.readSignal(i)\n",
    "\n",
    "                if 'normal' in fn:\n",
    "                    normal_label.append(0)\n",
    "                    normal_signal.append(sigbufs)\n",
    "                elif 'scare' in fn:\n",
    "                    scare_label.append(1)\n",
    "                    scare_signal.append(sigbufs)\n",
    "                elif 'touch' in fn:\n",
    "                    touch_label.append(2)\n",
    "                    touch_signal.append(sigbufs)\n",
    "                elif 'laugh' in fn:\n",
    "                    laugh_label.append(3)\n",
    "                    laugh_signal.append(sigbufs)\n",
    "                    \n",
    "                if DEBUG:\n",
    "                    print(sigbufs.shape)\n",
    "\n",
    "''' Labels --> 40 channels\n",
    "['COUNTER' 'INTERPOLATED' 'AF3' 'F7' 'F3' 'FC5' 'T7' 'P7' 'O1' 'O2' 'P8'\n",
    " 'T8' 'FC6' 'F4' 'F8' 'AF4' 'RAW_CQ' 'GYROX' 'GYROY' 'MARKER'\n",
    " 'MARKER_HARDWARE' 'SYNC' 'TIME_STAMP_s' 'TIME_STAMP_ms' 'CQ_AF3' 'CQ_F7'\n",
    " 'CQ_F3' 'CQ_FC5' 'CQ_T7' 'CQ_P7' 'CQ_O1' 'CQ_O2' 'CQ_P8' 'CQ_T8' 'CQ_FC6'\n",
    " 'CQ_F4' 'CQ_F8' 'CQ_AF4' 'CQ_CMS' 'CQ_DRL']\n",
    "'''\n",
    "\n",
    "print('Okay')\n",
    "if DEBUG:\n",
    "    print('normal signal length : ', len(normal_signal))\n",
    "    print('scare signal length : ', len(scare_signal))\n",
    "    print('touch signal length : ', len(touch_signal))\n",
    "    print('laugh signal length : ', len(laugh_signal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# PlotDataOnTimeDomain\n",
    "# Example:\n",
    "PlotDataOnTimeDomain(laugh_signal[10][13], 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Band Pass Filter to Make the Data Freqency between 1 Hz to 35 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example:\n",
    "BandPassData = BandPassFilter(laugh_signal[15][7], LowerFreqCut, HigherFreqCut, fs=Sample_frequency, order=BandPassOrder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define ICA (Independent Component Analyze) to find the main featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EEGICAModel = FastICA(n_components=1)\n",
    "ICAData = EEGICAModel.fit_transform(BandPassData.reshape(-1,1))\n",
    "PlotDataOnTimeDomain(ICAData, 128, -0.01, 0.01)\n",
    "ICAData = ICAData.reshape(313472)\n",
    "_, data = FFT(ICAData, sample_freq=Sample_frequency, data_length=ICAData.shape[0])\n",
    "PlotDataOnFreqDomain(data, Sample_frequency)\n",
    "print(BandPassData.shape)\n",
    "print(ICAData.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Ready to Convert Raw Data to ICA, BandPass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Normal Data Convert\n",
    "ICANormalSignalList = []   # New Noral Signal Data\n",
    "EEGICAModel = FastICA(n_components=1)  # ICA Model initialize\n",
    "ch_num = 1 \n",
    "\n",
    "if os.getcwd() != BandPassICAFigureSavingDirection:\n",
    "    os.chdir(BandPassICAFigureSavingDirection)\n",
    "_,files,_ = Get_file(BandPassICAFigureSavingDirection)\n",
    "if 'ICAFig' in files:\n",
    "    os.chdir('ICAFig')\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir('ICAFig')\n",
    "    os.chdir('ICAFig')\n",
    "\n",
    "for i in range(len(normal_signal)):\n",
    "    for ch in range(label_size):\n",
    "        if ch in channel_we_use:\n",
    "            BandPassData = BandPassFilter(normal_signal[i][ch], LowerFreqCut, HigherFreqCut, fs=Sample_frequency, order=BandPassOrder)\n",
    "            ICAData = EEGICAModel.fit_transform(BandPassData.reshape(-1,1))\n",
    "            ICANormalSignalList.append(ICAData)\n",
    "            \n",
    "            if SAVE_FIG:\n",
    "                fig = plt.gcf()   # Get Current Figure, 不加這行，save figire 時會存成白色\n",
    "                PlotDataOnTimeDomain(ICAData, 128, -0.02, 0.02, title='Normal,num:%d ' % (i+1) + 'ch:%d' % ch_num)\n",
    "\n",
    "                # Save the Figure\n",
    "                FigName = 'Normal_%d' % (i+1) + '_%d' % ch_num + '.png'\n",
    "                fig.savefig(FigName)\n",
    "            \n",
    "            ch_num += 1\n",
    "    ch_num = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scare Data Convert\n",
    "ICAScareSignalList = []   # New Noral Signal Data\n",
    "EEGICAModel = FastICA(n_components=1)  # ICA Model initialize\n",
    "ch_num = 1 \n",
    "\n",
    "if os.getcwd() != BandPassICAFigureSavingDirection:\n",
    "    os.chdir(BandPassICAFigureSavingDirection)\n",
    "_,files,_ = Get_file(BandPassICAFigureSavingDirection)\n",
    "if 'ICAFig' in files:\n",
    "    os.chdir('ICAFig')\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir('ICAFig')\n",
    "    os.chdir('ICAFig')\n",
    "\n",
    "for i in range(len(scare_signal)):\n",
    "    for ch in range(label_size):\n",
    "        if ch in channel_we_use:\n",
    "            BandPassData = BandPassFilter(scare_signal[i][ch], LowerFreqCut, HigherFreqCut, fs=Sample_frequency, order=BandPassOrder)\n",
    "            ICAData = EEGICAModel.fit_transform(BandPassData.reshape(-1,1))\n",
    "            ICAScareSignalList.append(ICAData)\n",
    "            \n",
    "            if SAVE_FIG:\n",
    "                fig = plt.gcf()   # Get Current Figure, 不加這行，save figire 時會存成白色\n",
    "                PlotDataOnTimeDomain(ICAData, 128, -0.02, 0.02, title='Scare,num:%d ' % (i+1) + 'ch:%d' % ch_num)\n",
    "\n",
    "                # Save the Figure\n",
    "                FigName = 'Scare_%d' % (i+1) + '_%d' % ch_num + '.png'\n",
    "                fig.savefig(FigName)\n",
    "\n",
    "            ch_num += 1\n",
    "    ch_num = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Touch Data Convert\n",
    "ICATouchSignalList = []   # New Noral Signal Data\n",
    "EEGICAModel = FastICA(n_components=1)  # ICA Model initialize\n",
    "ch_num = 1 \n",
    "\n",
    "if os.getcwd() != BandPassICAFigureSavingDirection:\n",
    "    os.chdir(BandPassICAFigureSavingDirection)\n",
    "_,files,_ = Get_file(BandPassICAFigureSavingDirection)\n",
    "if 'ICAFig' in files:\n",
    "    os.chdir('ICAFig')\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir('ICAFig')\n",
    "    os.chdir('ICAFig')\n",
    "\n",
    "for i in range(len(touch_signal)):\n",
    "    for ch in range(label_size):\n",
    "        if ch in channel_we_use:\n",
    "            BandPassData = BandPassFilter(touch_signal[i][ch], LowerFreqCut, HigherFreqCut, fs=Sample_frequency, order=BandPassOrder)\n",
    "            ICAData = EEGICAModel.fit_transform(BandPassData.reshape(-1,1))\n",
    "            ICATouchSignalList.append(ICAData)\n",
    "            \n",
    "            if SAVE_FIG:\n",
    "                fig = plt.gcf()   # Get Current Figure, 不加這行，save figire 時會存成白色\n",
    "                PlotDataOnTimeDomain(ICAData, 128, -0.02, 0.02, title='Touch,num:%d ' % (i+1) + 'ch:%d' % ch_num)\n",
    "\n",
    "                # Save the Figure\n",
    "                FigName = 'Touch_%d' % (i+1) + '_%d' % ch_num + '.png'\n",
    "                fig.savefig(FigName)\n",
    "\n",
    "            ch_num += 1\n",
    "    ch_num = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Laugh Data Convert\n",
    "ICALaughSignalList = []   # New Noral Signal Data\n",
    "EEGICAModel = FastICA(n_components=1)  # ICA Model initialize\n",
    "ch_num = 1 \n",
    "\n",
    "if os.getcwd() != BandPassICAFigureSavingDirection:\n",
    "    os.chdir(BandPassICAFigureSavingDirection)\n",
    "_,files,_ = Get_file(BandPassICAFigureSavingDirection)\n",
    "if 'ICAFig' in files:\n",
    "    os.chdir('ICAFig')\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir('ICAFig')\n",
    "    os.chdir('ICAFig')\n",
    "\n",
    "for i in range(len(laugh_signal)):\n",
    "    for ch in range(label_size):\n",
    "        if ch in channel_we_use:\n",
    "            BandPassData = BandPassFilter(laugh_signal[i][ch], LowerFreqCut, HigherFreqCut, fs=Sample_frequency, order=BandPassOrder)\n",
    "            ICAData = EEGICAModel.fit_transform(BandPassData.reshape(-1,1))\n",
    "            ICALaughSignalList.append(ICAData)\n",
    "            \n",
    "            if SAVE_FIG:\n",
    "                fig = plt.gcf()   # Get Current Figure, 不加這行，save figire 時會存成白色\n",
    "                PlotDataOnTimeDomain(ICAData, 128, -0.02, 0.02, title='Laugh,num:%d ' % (i+1) + 'ch:%d' % ch_num)\n",
    "\n",
    "                # Save the Figure\n",
    "                FigName = 'Laugh_%d' % (i+1) + '_%d' % ch_num + '.png'\n",
    "                fig.savefig(FigName)\n",
    "            \n",
    "            ch_num += 1\n",
    "    ch_num = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using FFT to Transfer time domain to frequency domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def SignalListTransToFFTList(SignalList, SAVE_FIG=False, SaveSignal=None, SaveDir=None):   # After BandPass, ICA algorithm\n",
    "    ch_num = 1\n",
    "    datanumber = 1\n",
    "    FFTSignalList = []\n",
    "    for i in range(len(SignalList)):\n",
    "        FreqList, FFTData = FFT(SignalList[i].reshape(-1), Sample_frequency, SignalList[i].shape[0])\n",
    "        \n",
    "        if SAVE_FIG:\n",
    "            if os.getcwd() != BandPassICAFigureSavingDirection:\n",
    "                os.chdir(BandPassICAFigureSavingDirection)\n",
    "            _,files,_ = Get_file(BandPassICAFigureSavingDirection)\n",
    "            if 'FFTFig' in files:\n",
    "                os.chdir('FFTFig')\n",
    "                pass\n",
    "            else:\n",
    "                os.mkdir('FFTFig')\n",
    "                os.chdir('FFTFig')\n",
    "            if SaveSignal is None:\n",
    "                print('Warning! Saved figure not define...')\n",
    "            TitleName = 'F' + str(SaveSignal) + '_%d'%datanumber + '_%d'%ch_num\n",
    "            fig = plt.gcf()   # Get Current Figure, 不加這行，save figire 時會存成白色\n",
    "            PlotDataOnFreqDomain(FFTData, Sample_frequency, LowerFreq=LowerFreqCut, HigherFreq=HigherFreqCut,\n",
    "                                title=TitleName)\n",
    "            fig.savefig(TitleName+'.png')\n",
    "        \n",
    "        FFTDataFreqWeWant = (FreqList>=8)\n",
    "        NewFFTData = FFTData*FFTDataFreqWeWant\n",
    "        FFTDataFreqWeWant = (FreqList<=30)\n",
    "        NewFFTData = NewFFTData*FFTDataFreqWeWant\n",
    "        DeleteZeroValuePos = np.where(NewFFTData==0)\n",
    "        NewFFTData = np.delete(NewFFTData, DeleteZeroValuePos)\n",
    "        FFTSignalList.append(NewFFTData)\n",
    "        ch_num += 1\n",
    "        if ch_num >14:\n",
    "            ch_num = 1\n",
    "            datanumber += 1\n",
    "    return FFTSignalList\n",
    "    \n",
    "FFTNormalList = SignalListTransToFFTList(ICANormalSignalList, SAVE_FIG=False, SaveSignal='Normal', SaveDir=BandPassICAFigureSavingDirection)\n",
    "FFTScareList = SignalListTransToFFTList(ICAScareSignalList, SAVE_FIG=False, SaveSignal='Scare', SaveDir=BandPassICAFigureSavingDirection)\n",
    "FFTTouchList = SignalListTransToFFTList(ICATouchSignalList, SAVE_FIG=False, SaveSignal='Touch', SaveDir=BandPassICAFigureSavingDirection)\n",
    "FFTLaughList = SignalListTransToFFTList(ICALaughSignalList, SAVE_FIG=False, SaveSignal='Laugh', SaveDir=BandPassICAFigureSavingDirection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the data shape\n",
    "print('Normal', len(FFTNormalList))\n",
    "print('Scare', len(FFTScareList))\n",
    "print('Touch', len(FFTTouchList))\n",
    "print('Laugh', len(FFTLaughList))\n",
    "FFTNormalArray = np.asarray(FFTNormalList, dtype=np.float32)\n",
    "FFTScareArray = np.asarray(FFTScareList, dtype=np.float32)\n",
    "FFTTouchArray = np.asarray(FFTTouchList, dtype=np.float32)\n",
    "FFTLaughArray = np.asarray(FFTLaughList, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEGPCAModel = PCA(n_components=128)\n",
    "PCANormalArray = EEGPCAModel.fit_transform(FFTNormalArray)\n",
    "PCAScareArray = EEGPCAModel.fit_transform(FFTScareArray)\n",
    "PCATouchArray = EEGPCAModel.fit_transform(FFTTouchArray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    print('normal size (alpha, beta) : ', normal_alpha.shape, normal_beta.shape)\n",
    "    print('scare size (alpha, beta)  : ', scare_alpha.shape, scare_beta.shape)\n",
    "    print('touch size (alpha, beta)  : ', touch_alpha.shape, touch_beta.shape)\n",
    "    print('laugh size (alpha, beta)  : ', laugh_alpha.shape, laugh_beta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the target\n",
    "normal_target = np.ones([normal_alpha.shape[2]]) * 1\n",
    "scare_target = np.ones([scare_alpha.shape[2]]) * 2\n",
    "touch_target = np.ones([touch_alpha.shape[2]]) * 3\n",
    "laugh_target = np.ones([laugh_alpha.shape[2]]) * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = 0\n",
    "y = 0\n",
    "for ch in range(len(channel_we_use)):\n",
    "    X1 = np.vstack((normal_alpha[:,ch,:].reshape([17,64]),\n",
    "                         scare_alpha[:,ch,:].reshape([11,64]),\n",
    "                        touch_alpha[:,ch,:].reshape([10,64]),\n",
    "                        laugh_alpha[:,ch,:].reshape([17,64])))\n",
    "    X2 = np.vstack((normal_beta[:,ch,:].reshape([17,64]),\n",
    "                         scare_beta[:,ch,:].reshape([11,64]),\n",
    "                        touch_beta[:,ch,:].reshape([10,64]),\n",
    "                        laugh_beta[:,ch,:].reshape([17,64])))\n",
    "    X_all = np.hstack((X1,X2))\n",
    "    y_all = np.hstack((normal_target,\n",
    "                   scare_target,\n",
    "                   touch_target,\n",
    "                   laugh_target)).reshape(-1)\n",
    "    try:\n",
    "        X = np.vstack((X,X_all))\n",
    "        y = np.hstack((y,y_all))\n",
    "    except Exception as e:\n",
    "        X = X_all\n",
    "        y = y_all\n",
    "        print(e)\n",
    "    if DEBUG:\n",
    "        if i > 0:\n",
    "            print(X.shape, X_all.shape)\n",
    "            print(y.shape, y_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    print(X.shape)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from Danny_ML_CLF import Danny_ML_CLF\n",
    "# clf = Danny_ML_CLF()\n",
    "# train_X, test_X, train_y, test_y = clf.Split_data(X, y, test_size=0.3, Standard=True)\n",
    "# clf.Fit_value(train_X, train_y)\n",
    "# clf.Train()\n",
    "# clf.Report(test_X, test_y, [1,2,3,4], show_cm=False)\n",
    "# clf.Report2txt('EEG_Report.txt')\n",
    "# print('Report Okay !\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot_y = y[:,np.newaxis]\n",
    "one_hot = OneHotEncoder()\n",
    "one_hot.fit(one_hot_y)\n",
    "one_hot_y = one_hot.transform(one_hot_y).toarray()\n",
    "print(one_hot_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, one_hot_y, test_size=0.3)\n",
    "def next_batch(num, data, labels):\n",
    "\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = data[idx]\n",
    "    labels_shuffle = labels[idx]\n",
    "    #labels_shuffle = np.asarray(labels_shuffle.values.reshape(len(labels_shuffle), 1))\n",
    "\n",
    "    return data_shuffle, labels_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_X = tf.placeholder(tf.float32, [None, 128])\n",
    "tf_y = tf.placeholder(tf.float32, [None, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neural Network Design\n",
    "layer1 = tf.layers.dense(tf_X, 500, activation=tf.nn.relu)\n",
    "hidden1 = tf.layers.dense(layer1, 200, activation=tf.nn.relu)\n",
    "dropout1 = tf.layers.dropout(hidden1, rate=0.4)\n",
    "hidden2 = tf.layers.dense(dropout1, 200, activation=tf.nn.relu)\n",
    "pred = tf.layers.dense(hidden2, 4, activation=tf.nn.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "# Calculate Loss (for both TRAIN and EVAL modes)\n",
    "loss_func = tf.losses.softmax_cross_entropy(onehot_labels=tf_y, logits=pred)\n",
    "train = tf.train.AdamOptimizer(0.01).minimize(loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the accuracy\n",
    "accuracy = tf.metrics.accuracy(labels=tf.argmax(tf_y, axis=1),\n",
    "                               predictions=tf.argmax(pred, axis=1))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)     # initialize var in graph\n",
    "losses = []\n",
    "for i in range(3000):\n",
    "    b_x, b_y = next_batch(20, train_X, train_y)\n",
    "    feed_dict = feed_dict={tf_X:train_X, tf_y:train_y}\n",
    "    sess.run(train, feed_dict=feed_dict)\n",
    "    losses.append(sess.run(loss_func, feed_dict=feed_dict))\n",
    "    if i%50 == 0:\n",
    "        print(losses[-1])\n",
    "    \n",
    "def plot_loss(loss_data):\n",
    "    loss_size = len(losses)\n",
    "    loss_x = np.linspace(1,loss_size,loss_size)\n",
    "    plt.plot(loss_x, loss_data)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "plot_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
